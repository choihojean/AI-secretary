{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pygame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import time\n",
    "\n",
    "client = OpenAI()\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr\n",
    "\n",
    "r = sr.Recognizer()\n",
    "\n",
    "with sr.Microphone() as source:\n",
    "    print('Speak Anything :')\n",
    "    audio = r.listen(source)\n",
    "    \n",
    "    try:\n",
    "        text = r.recognize_google(audio, language='ko-KR')\n",
    "        print('You said : {}'.format(text))\n",
    "    except sr.UnknownValueError:\n",
    "        print('Sorry could not recognize your voice')\n",
    "    except sr.RequestError as e:\n",
    "        print('Could not request results from Google Speech Recognition service; {0}'.format(e))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr\n",
    "import gradio as gr\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from gtts import gTTS\n",
    "import pygame\n",
    "import time\n",
    "\n",
    "client = OpenAI()\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "#OpenAI API에게서 응답을 받기 위한 코드\n",
    "def get_response_from_openai(text):\n",
    "    messages = [{\"role\": \"user\", \"content\": text}]\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=messages,\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "\n",
    "# 음성 인식을 위한 설정\n",
    "r = sr.Recognizer()\n",
    "\n",
    "with sr.Microphone() as source:\n",
    "    print('Speak Anything :')\n",
    "    audio = r.listen(source)\n",
    "    \n",
    "    try:\n",
    "        text = r.recognize_google(audio, language='ko-KR')\n",
    "        print('You said : {}'.format(text))\n",
    "        \n",
    "        # OpenAI API로 응답 받기\n",
    "        response = get_response_from_openai(text)\n",
    "        print('OpenAI response: ', response)\n",
    "\n",
    "        tts = gTTS(text=response, lang='ko')\n",
    "        tts.save(\"response.mp3\")\n",
    "        \n",
    "        # Pygame을 사용하여 음성 파일 재생\n",
    "        pygame.mixer.init()\n",
    "        pygame.mixer.music.load(\"response.mp3\")\n",
    "        pygame.mixer.music.play()\n",
    "\n",
    "        # 음악 재생이 완료될 때까지 대기\n",
    "        while pygame.mixer.music.get_busy():\n",
    "            pygame.time.Clock().tick(10)\n",
    "        \n",
    "    except sr.UnknownValueError:\n",
    "        print('Sorry could not recognize your voice')\n",
    "    except sr.RequestError as e:\n",
    "        print('Could not request results from Google Speech Recognition service; {0}'.format(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import speech_recognition as sr\n",
    "from gtts import gTTS\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import tempfile\n",
    "\n",
    "# 환경 변수 로드\n",
    "load_dotenv()\n",
    "client = OpenAI()\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "\n",
    "# OpenAI API로부터 응답 받는 함수\n",
    "def get_response_from_openai(text):\n",
    "    messages = [{\"role\": \"user\", \"content\": text}]\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=messages,\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# 음성 인식 및 음성 응답 생성\n",
    "def process_voice(file):\n",
    "    r = sr.Recognizer()\n",
    "    with sr.AudioFile(file) as source:\n",
    "        audio = r.record(source)\n",
    "    \n",
    "    try:\n",
    "        # 음성 인식\n",
    "        text = r.recognize_google(audio, language='ko-KR')\n",
    "        # OpenAI API로 응답 받기\n",
    "        response = get_response_from_openai(text)\n",
    "        # 응답을 음성으로 변환\n",
    "        tts = gTTS(text=response, lang='ko')\n",
    "        \n",
    "        # 음성을 임시 파일로 저장\n",
    "        temp_file = tempfile.NamedTemporaryFile(delete=False, suffix='.mp3')\n",
    "        tts.save(temp_file.name)\n",
    "        temp_file.close()  # 파일 사용이 끝난 후 파일을 닫아야 함\n",
    "        return temp_file.name  # 파일 경로 반환\n",
    "    except sr.UnknownValueError:\n",
    "        return \"Sorry, could not recognize your voice.\"\n",
    "    except sr.RequestError as e:\n",
    "        return f\"Could not request results from Google Speech Recognition service; {e}\"\n",
    "\n",
    "# 그레디오 인터페이스 설정\n",
    "demo = gr.Interface(\n",
    "    fn=process_voice,\n",
    "    inputs=gr.Audio(type=\"filepath\", label=\"Record your question\"),\n",
    "    outputs=gr.Audio(label=\"Response\"),\n",
    "    title=\"Voice to OpenAI Response\",\n",
    "    description=\"Speak and receive a response from OpenAI.\"\n",
    ")\n",
    "\n",
    "# 인터페이스 실행\n",
    "demo.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7902\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7902/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:    Exception in ASGI application\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\anaconda\\Lib\\site-packages\\uvicorn\\protocols\\http\\h11_impl.py\", line 407, in run_asgi\n",
      "    result = await app(  # type: ignore[func-returns-value]\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\anaconda\\Lib\\site-packages\\uvicorn\\middleware\\proxy_headers.py\", line 69, in __call__\n",
      "    return await self.app(scope, receive, send)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\anaconda\\Lib\\site-packages\\fastapi\\applications.py\", line 1054, in __call__\n",
      "    await super().__call__(scope, receive, send)\n",
      "  File \"c:\\anaconda\\Lib\\site-packages\\starlette\\applications.py\", line 123, in __call__\n",
      "    await self.middleware_stack(scope, receive, send)\n",
      "  File \"c:\\anaconda\\Lib\\site-packages\\starlette\\middleware\\errors.py\", line 186, in __call__\n",
      "    raise exc\n",
      "  File \"c:\\anaconda\\Lib\\site-packages\\starlette\\middleware\\errors.py\", line 164, in __call__\n",
      "    await self.app(scope, receive, _send)\n",
      "  File \"c:\\anaconda\\Lib\\site-packages\\gradio\\route_utils.py\", line 707, in __call__\n",
      "    await self.app(scope, receive, send)\n",
      "  File \"c:\\anaconda\\Lib\\site-packages\\starlette\\middleware\\exceptions.py\", line 65, in __call__\n",
      "    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n",
      "  File \"c:\\anaconda\\Lib\\site-packages\\starlette\\_exception_handler.py\", line 64, in wrapped_app\n",
      "    raise exc\n",
      "  File \"c:\\anaconda\\Lib\\site-packages\\starlette\\_exception_handler.py\", line 53, in wrapped_app\n",
      "    await app(scope, receive, sender)\n",
      "  File \"c:\\anaconda\\Lib\\site-packages\\starlette\\routing.py\", line 756, in __call__\n",
      "    await self.middleware_stack(scope, receive, send)\n",
      "  File \"c:\\anaconda\\Lib\\site-packages\\starlette\\routing.py\", line 776, in app\n",
      "    await route.handle(scope, receive, send)\n",
      "  File \"c:\\anaconda\\Lib\\site-packages\\starlette\\routing.py\", line 297, in handle\n",
      "    await self.app(scope, receive, send)\n",
      "  File \"c:\\anaconda\\Lib\\site-packages\\starlette\\routing.py\", line 77, in app\n",
      "    await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n",
      "  File \"c:\\anaconda\\Lib\\site-packages\\starlette\\_exception_handler.py\", line 64, in wrapped_app\n",
      "    raise exc\n",
      "  File \"c:\\anaconda\\Lib\\site-packages\\starlette\\_exception_handler.py\", line 53, in wrapped_app\n",
      "    await app(scope, receive, sender)\n",
      "  File \"c:\\anaconda\\Lib\\site-packages\\starlette\\routing.py\", line 75, in app\n",
      "    await response(scope, receive, send)\n",
      "  File \"c:\\anaconda\\Lib\\site-packages\\starlette\\responses.py\", line 352, in __call__\n",
      "    await send(\n",
      "  File \"c:\\anaconda\\Lib\\site-packages\\starlette\\_exception_handler.py\", line 50, in sender\n",
      "    await send(message)\n",
      "  File \"c:\\anaconda\\Lib\\site-packages\\starlette\\_exception_handler.py\", line 50, in sender\n",
      "    await send(message)\n",
      "  File \"c:\\anaconda\\Lib\\site-packages\\starlette\\middleware\\errors.py\", line 161, in _send\n",
      "    await send(message)\n",
      "  File \"c:\\anaconda\\Lib\\site-packages\\uvicorn\\protocols\\http\\h11_impl.py\", line 504, in send\n",
      "    output = self.conn.send(event=h11.Data(data=data))\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\anaconda\\Lib\\site-packages\\h11\\_connection.py\", line 512, in send\n",
      "    data_list = self.send_with_data_passthrough(event)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\anaconda\\Lib\\site-packages\\h11\\_connection.py\", line 545, in send_with_data_passthrough\n",
      "    writer(event, data_list.append)\n",
      "  File \"c:\\anaconda\\Lib\\site-packages\\h11\\_writers.py\", line 65, in __call__\n",
      "    self.send_data(event.data, write)\n",
      "  File \"c:\\anaconda\\Lib\\site-packages\\h11\\_writers.py\", line 91, in send_data\n",
      "    raise LocalProtocolError(\"Too much data for declared Content-Length\")\n",
      "h11._util.LocalProtocolError: Too much data for declared Content-Length\n",
      "ERROR:    Exception in ASGI application\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\anaconda\\Lib\\site-packages\\uvicorn\\protocols\\http\\h11_impl.py\", line 407, in run_asgi\n",
      "    result = await app(  # type: ignore[func-returns-value]\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\anaconda\\Lib\\site-packages\\uvicorn\\middleware\\proxy_headers.py\", line 69, in __call__\n",
      "    return await self.app(scope, receive, send)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\anaconda\\Lib\\site-packages\\fastapi\\applications.py\", line 1054, in __call__\n",
      "    await super().__call__(scope, receive, send)\n",
      "  File \"c:\\anaconda\\Lib\\site-packages\\starlette\\applications.py\", line 123, in __call__\n",
      "    await self.middleware_stack(scope, receive, send)\n",
      "  File \"c:\\anaconda\\Lib\\site-packages\\starlette\\middleware\\errors.py\", line 186, in __call__\n",
      "    raise exc\n",
      "  File \"c:\\anaconda\\Lib\\site-packages\\starlette\\middleware\\errors.py\", line 164, in __call__\n",
      "    await self.app(scope, receive, _send)\n",
      "  File \"c:\\anaconda\\Lib\\site-packages\\gradio\\route_utils.py\", line 707, in __call__\n",
      "    await self.app(scope, receive, send)\n",
      "  File \"c:\\anaconda\\Lib\\site-packages\\starlette\\middleware\\exceptions.py\", line 65, in __call__\n",
      "    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n",
      "  File \"c:\\anaconda\\Lib\\site-packages\\starlette\\_exception_handler.py\", line 64, in wrapped_app\n",
      "    raise exc\n",
      "  File \"c:\\anaconda\\Lib\\site-packages\\starlette\\_exception_handler.py\", line 53, in wrapped_app\n",
      "    await app(scope, receive, sender)\n",
      "  File \"c:\\anaconda\\Lib\\site-packages\\starlette\\routing.py\", line 756, in __call__\n",
      "    await self.middleware_stack(scope, receive, send)\n",
      "  File \"c:\\anaconda\\Lib\\site-packages\\starlette\\routing.py\", line 776, in app\n",
      "    await route.handle(scope, receive, send)\n",
      "  File \"c:\\anaconda\\Lib\\site-packages\\starlette\\routing.py\", line 297, in handle\n",
      "    await self.app(scope, receive, send)\n",
      "  File \"c:\\anaconda\\Lib\\site-packages\\starlette\\routing.py\", line 77, in app\n",
      "    await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n",
      "  File \"c:\\anaconda\\Lib\\site-packages\\starlette\\_exception_handler.py\", line 64, in wrapped_app\n",
      "    raise exc\n",
      "  File \"c:\\anaconda\\Lib\\site-packages\\starlette\\_exception_handler.py\", line 53, in wrapped_app\n",
      "    await app(scope, receive, sender)\n",
      "  File \"c:\\anaconda\\Lib\\site-packages\\starlette\\routing.py\", line 75, in app\n",
      "    await response(scope, receive, send)\n",
      "  File \"c:\\anaconda\\Lib\\site-packages\\starlette\\responses.py\", line 352, in __call__\n",
      "    await send(\n",
      "  File \"c:\\anaconda\\Lib\\site-packages\\starlette\\_exception_handler.py\", line 50, in sender\n",
      "    await send(message)\n",
      "  File \"c:\\anaconda\\Lib\\site-packages\\starlette\\_exception_handler.py\", line 50, in sender\n",
      "    await send(message)\n",
      "  File \"c:\\anaconda\\Lib\\site-packages\\starlette\\middleware\\errors.py\", line 161, in _send\n",
      "    await send(message)\n",
      "  File \"c:\\anaconda\\Lib\\site-packages\\uvicorn\\protocols\\http\\h11_impl.py\", line 511, in send\n",
      "    output = self.conn.send(event=h11.EndOfMessage())\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\anaconda\\Lib\\site-packages\\h11\\_connection.py\", line 512, in send\n",
      "    data_list = self.send_with_data_passthrough(event)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\anaconda\\Lib\\site-packages\\h11\\_connection.py\", line 545, in send_with_data_passthrough\n",
      "    writer(event, data_list.append)\n",
      "  File \"c:\\anaconda\\Lib\\site-packages\\h11\\_writers.py\", line 67, in __call__\n",
      "    self.send_eom(event.headers, write)\n",
      "  File \"c:\\anaconda\\Lib\\site-packages\\h11\\_writers.py\", line 96, in send_eom\n",
      "    raise LocalProtocolError(\"Too little data for declared Content-Length\")\n",
      "h11._util.LocalProtocolError: Too little data for declared Content-Length\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import speech_recognition as sr\n",
    "from gtts import gTTS\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import tempfile\n",
    "\n",
    "# 환경 변수 로드\n",
    "load_dotenv()\n",
    "client = OpenAI()\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "history = []\n",
    "# OpenAI API로부터 응답 받는 함수\n",
    "def get_response_from_openai(text):\n",
    "    global history\n",
    "    history.append({\"role\": \"user\", \"content\": text})\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=history,\n",
    "    )\n",
    "    history.append({\"role\":\"assistant\",\"content\":response.choices[0].message.content})\n",
    "    return response.choices[0].message.content, history\n",
    "\n",
    "# 음성 인식 및 음성 응답 생성\n",
    "def process_voice(file, reset_history=False):\n",
    "    if reset_history:\n",
    "        global history\n",
    "        history=[]\n",
    "\n",
    "    r = sr.Recognizer()\n",
    "    with sr.AudioFile(file) as source:\n",
    "        audio = r.record(source)\n",
    "    \n",
    "    try:\n",
    "        # 음성 인식\n",
    "        text = r.recognize_google(audio, language='ko-KR')\n",
    "        # OpenAI API로 응답 받기\n",
    "        response, history_display = get_response_from_openai(text)\n",
    "        # 응답을 음성으로 변환\n",
    "        tts = gTTS(text=response, lang='ko')\n",
    "        \n",
    "        # 음성을 임시 파일로 저장\n",
    "        temp_file = tempfile.NamedTemporaryFile(delete=False, suffix='.mp3')\n",
    "        tts.save(temp_file.name)\n",
    "        temp_file.close()  # 파일 사용이 끝난 후 파일을 닫아야 함\n",
    "        return temp_file.name, history_display  # 파일 경로 반환\n",
    "    except sr.UnknownValueError:\n",
    "        return \"목소리를 인식하지 못했습니다.\", history\n",
    "    except sr.RequestError as e:\n",
    "        return f\"Speech Recognition으로부터 결과를 받을 수 없습니다. {e}\", history\n",
    "\n",
    "# Gradio 인터페이스 설정\n",
    "demo = gr.Interface(\n",
    "    fn=process_voice,\n",
    "    inputs=[gr.Audio(type=\"filepath\", label=\"질문\"),gr.Checkbox(label=\"대화 내역 지우기\")],\n",
    "    outputs=[gr.Audio(label=\"AI비서\"),gr.JSON(label=\"대화 내역\")],\n",
    "    title=\"음성 AI비서\",\n",
    "    description=\"음성으로 AI와 대화를 나누어보세요\"\n",
    ")\n",
    "\n",
    "# 인터페이스 실행\n",
    "demo.launch()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
